{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Customer Segmentation / Clustering\n",
    "\n",
    "Perform customer segmentation using clustering techniques. Use both profile information (from Customers.csv) and transaction information (from Transactions.csv).\n",
    "- You have the flexibility to choose any clustering algorithm and any number of clusters in between(2 and 10)\n",
    "- Calculate clustering metrics, including the DB Index(Evaluation will be done on this).\n",
    "- Visualise your clusters using relevant plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import davies_bouldin_score, silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customers = pd.read_csv(\"/home/dispers/PRACHI/Customers.csv\")\n",
    "df_products = pd.read_csv(\"/home/dispers/PRACHI/Products.csv\")\n",
    "df_txns = pd.read_csv(\"/home/dispers/PRACHI/Transactions.csv\")\n",
    "\n",
    "df_merged = pd.merge(df_txns, df_products, how = \"left\", on = [\"ProductID\",\"Price\"])\n",
    "df_merged = pd.merge(df_merged, df_customers, how = \"left\", on = \"CustomerID\")\n",
    "df_merged = pd.get_dummies(df_merged, columns=['Region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged['SignupMonth'] = pd.to_datetime(df_merged['SignupDate']).dt.month\n",
    "df_merged['TransactionMonth'] = pd.to_datetime(df_merged['TransactionDate']).dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_profiles = df_merged.groupby('CustomerID').agg({\n",
    "    'TotalValue': 'sum',\n",
    "    'TransactionID':'count',\n",
    "    'Quantity':'sum',\n",
    "    # 'SignupMonth': 'first',                       # Month of signup\n",
    "    'TransactionMonth': lambda x: x.mode()[0],    # Top month of transaction\n",
    "    'Region_Asia': 'first',\n",
    "    'Region_Europe': 'first',\n",
    "    'Region_North America': 'first',\n",
    "    'Region_South America': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "# cust_profiles['Region'] = df_merged.groupby('CustomerID')[['Region_Asia', 'Region_Europe', 'Region_North America', 'Region_South America']]\n",
    "cust_profiles['AvgTransactionValue'] = cust_profiles['TotalValue'] / cust_profiles['TransactionID']\n",
    "cust_profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import davies_bouldin_score, silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# # Load data\n",
    "# customers = pd.read_csv('Customers.csv')\n",
    "# transactions = pd.read_csv('Transactions.csv')\n",
    "\n",
    "# # Merge datasets\n",
    "# df_merged = pd.merge(transactions, customers, on='CustomerID')\n",
    "\n",
    "# # Aggregate features\n",
    "# cust_profiles = df_merged.groupby('CustomerID').agg({\n",
    "#     'TotalValue': 'sum',  # Total transaction value\n",
    "#     'TransactionID': 'count',  # Number of transactions\n",
    "#     'Quantity': 'sum',  # Total quantity purchased\n",
    "#     # 'Age': 'mean',  # Customer's age\n",
    "#     # 'Income': 'mean'  # Customer's income\n",
    "# }).reset_index()\n",
    "\n",
    "# Data Preprocessing\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(cust_profiles.iloc[:, 1:])\n",
    "\n",
    "# Clustering with KMeans\n",
    "db_scores = []\n",
    "silhouette_scores = []\n",
    "inertia_values = []\n",
    "num_clusters = range(2, 11)\n",
    "\n",
    "for k in num_clusters:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=1)\n",
    "    labels = kmeans.fit_predict(scaled_features)\n",
    "    db_index = davies_bouldin_score(scaled_features, labels)\n",
    "    silhouette_avg = silhouette_score(scaled_features, labels)\n",
    "    inertia = kmeans.inertia_\n",
    "    \n",
    "    db_scores.append(db_index)\n",
    "    silhouette_scores.append(silhouette_avg)\n",
    "    inertia_values.append(inertia)\n",
    "\n",
    "# Determine optimal number of clusters (minimizing DB Index)\n",
    "optimal_k = num_clusters[np.argmin(db_scores)]\n",
    "print(f\"Optimal number of clusters: {optimal_k}\")\n",
    "\n",
    "# Summary of clustering metrics\n",
    "print(\"\\nClustering Metrics Summary:\")\n",
    "for k, db, sil, inertia in zip(num_clusters, db_scores, silhouette_scores, inertia_values):\n",
    "    print(f\"Clusters: {k}, DB Index: {db:.2f}, Silhouette Score: {sil:.2f}, Inertia: {inertia:.2f}\")\n",
    "\n",
    "# Fit KMeans with optimal clusters\n",
    "kmeans_optimal = KMeans(n_clusters=optimal_k, random_state=42)\n",
    "cust_profiles['Cluster'] = kmeans_optimal.fit_predict(scaled_features)\n",
    "\n",
    "# Evaluate DB Index for optimal clustering\n",
    "optimal_db_index = davies_bouldin_score(scaled_features, cust_profiles['Cluster'])\n",
    "optimal_silhouette = silhouette_score(scaled_features, cust_profiles['Cluster'])\n",
    "\n",
    "print(f\"\\nMetrics for {optimal_k} Clusters:\")\n",
    "print(f\"Davies-Bouldin Index: {optimal_db_index:.2f}\")\n",
    "print(f\"Silhouette Score: {optimal_silhouette:.2f}\")\n",
    "\n",
    "# Visualization of Clusters\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(\n",
    "    x=cust_profiles['Quantity'],\n",
    "    y=cust_profiles['TotalValue'],\n",
    "    hue=cust_profiles['Cluster'],\n",
    "    palette='viridis',\n",
    "    s=100\n",
    ")\n",
    "plt.title('Customer Segmentation')\n",
    "plt.xlabel('Quantity Purchased')\n",
    "plt.ylabel('Total Value')\n",
    "plt.legend(title='Cluster', loc='upper right')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Pairplot for feature relationships\n",
    "sns.pairplot(\n",
    "    cust_profiles,\n",
    "    vars=['TotalValue', 'TransactionID', 'Quantity'],\n",
    "    hue='Cluster',\n",
    "    palette='viridis'\n",
    ")\n",
    "plt.suptitle('Cluster Relationships', y=1.02)\n",
    "plt.show()\n",
    "\n",
    "# Save results to a CSV\n",
    "cust_profiles.to_csv('Customer_Clusters.csv', index=False)\n",
    "print(\"Customer_Clusters.csv created successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
